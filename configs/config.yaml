# Multimodal Emotion Recognition Configuration

# =============================================================================
# DATA CONFIGURATION
# =============================================================================
data:
  fer2013:
    path: "data/fer2013"
    image_size: 48
    num_classes: 7
    emotions: ["Angry", "Disgust", "Fear", "Happy", "Sad", "Surprise", "Neutral"]
    train_split: 0.8
    val_split: 0.1
    test_split: 0.1
  
  ravdess:
    path: "data/ravdess"
    sample_rate: 22050
    duration: 3  # seconds
    num_classes: 8
    emotions: ["Neutral", "Calm", "Happy", "Sad", "Angry", "Fearful", "Disgust", "Surprised"]
    n_mfcc: 40
    n_mels: 128
    train_split: 0.8
    val_split: 0.1
    test_split: 0.1

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
models:
  facial:
    architecture: "custom_cnn"  # Options: custom_cnn, vgg16, resnet50, mobilenet
    input_shape: [48, 48, 1]
    dropout_rate: 0.5
    l2_regularization: 0.01
  
  speech:
    architecture: "cnn_lstm"  # Options: cnn_lstm, lstm, cnn
    input_shape: [40, 130, 1]  # MFCC shape: (n_mfcc, time_steps, channels)
    lstm_units: 128
    dropout_rate: 0.3
  
  fusion:
    method: "concatenate"  # Options: concatenate, attention, weighted
    dense_units: [256, 128]
    dropout_rate: 0.4
    num_classes: 7  # Common emotions between datasets

# =============================================================================
# TRAINING CONFIGURATION
# =============================================================================
training:
  facial:
    batch_size: 64
    epochs: 50
    learning_rate: 0.001
    optimizer: "adam"
    early_stopping_patience: 10
    reduce_lr_patience: 5
    reduce_lr_factor: 0.5
  
  speech:
    batch_size: 32
    epochs: 50
    learning_rate: 0.001
    optimizer: "adam"
    early_stopping_patience: 10
    reduce_lr_patience: 5
    reduce_lr_factor: 0.5
  
  fusion:
    batch_size: 32
    epochs: 30
    learning_rate: 0.0001
    optimizer: "adam"
    early_stopping_patience: 10
    reduce_lr_patience: 5
    reduce_lr_factor: 0.5

# =============================================================================
# PATHS CONFIGURATION
# =============================================================================
paths:
  checkpoints: "outputs/checkpoints"
  logs: "outputs/logs"
  results: "outputs/results"
  models:
    facial: "models/facial"
    speech: "models/speech"
    fusion: "models/fusion"

# =============================================================================
# INFERENCE CONFIGURATION
# =============================================================================
inference:
  use_webcam: true
  use_microphone: true
  confidence_threshold: 0.5
  display_probabilities: true
  frame_skip: 2  # Process every nth frame for performance

# =============================================================================
# COMMON EMOTIONS (Mapped between datasets)
# =============================================================================
common_emotions:
  - "Angry"
  - "Disgust"
  - "Fear"
  - "Happy"
  - "Sad"
  - "Surprise"
  - "Neutral"
